### 1.适用场景
卓越的推理性能：利用 TensorRT 和 GPU 的强大功能，Triton 提供了高效的推理服务，非常适合需要高实时性的应用场景，如自动驾驶技术

Triton 推理服务器的工作流程简洁高效：首先接收来自 HTTP/REST、gRPC 或 C API 的推理请求，然后将这些请求路由至对应模型的调度队列中；接着，调度器可能会对请求进行批处理，并将其传递给相应的模型后端执行推理；最终，推理结果将被返回给请求方。此外，Triton 架构设计支持在同一系统上并行运行多个模型或同一模型的多个实例，无论系统配置有多少块 GPU 卡（0个、1个或多个）。
